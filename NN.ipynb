{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch,sklearn\n",
    "from sklearn import model_selection\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torcheval import metrics\n",
    "import time\n",
    "import uuid\n",
    "import kalshi_python\n",
    "from kalshi_python.models import *\n",
    "import pickle\n",
    "import requests\n",
    "import ast\n",
    "import json\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self,input_size,h1,h2):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.h1 = h1\n",
    "        self.h2 = h2\n",
    "        self.layers = self.get_fc_layers()\n",
    "\n",
    "    def get_fc_layers(self):\n",
    "        layers = nn.Sequential(\n",
    "            nn.Linear(self.input_size, self.h1,dtype = torch.float64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.h1, self.h2,dtype = torch.float64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.h2, 1,dtype = torch.float64),\n",
    "           )\n",
    "        return layers\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = self.layers(input)\n",
    "        return x\n",
    "\n",
    "    def month_fun(self,m):\n",
    "            d = {1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0,10:0,11:0,12:0}\n",
    "            d[m] += 1.0\n",
    "            return d\n",
    "\n",
    "    def stat_fun(self,s):\n",
    "            d = {'USW00012839' : 0, 'USW00014819' :0, 'USW00013904' :0, 'USW00094728': 0}\n",
    "            d[s] += 1.0\n",
    "            return d\n",
    "\n",
    "    def load_data(self,datastr : str,features,target):\n",
    "        dataset = pd.read_csv(datastr)\n",
    "        dataset = dataset[features+[target,\"STATION\",\"Month\"]]\n",
    "        dataset.dropna(inplace=True)\n",
    "        dataset[target] = dataset[target].astype(\"float\")\n",
    "        for f in features:\n",
    "            dataset[f] = dataset[f].astype(\"float\")\n",
    "        dataset[[\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]] = \\\n",
    "            dataset.apply(lambda x : self.month_fun(x[\"Month\"]),axis = 1,result_type=\"expand\")\n",
    "        dataset[['USW00012839', 'USW00014819', 'USW00013904', 'USW00094728']] =\\\n",
    "                dataset.apply(lambda x : self.stat_fun(x[\"STATION\"]),axis = 1, result_type=\"expand\")\n",
    "        dataset.dropna(inplace=True)\n",
    "        dataset.drop(columns = [\"Month\",\"STATION\"],inplace = True)\n",
    "        train,test = model_selection.train_test_split(dataset,test_size = 0.1,random_state = 3)\n",
    "        train_x = train.drop(columns = [target])\n",
    "        train_y = train[target]\n",
    "        test_x = test.drop(columns = [target])\n",
    "        test_y = test[target]\n",
    "        self.train_x,self.train_y,self.test_x,self.test_y = train_x,train_y,test_x,test_y\n",
    "        \n",
    "    def train(self):\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.003)\n",
    "        train_loader = DataLoader(list(zip(torch.tensor(self.train_x.values),torch.tensor(self.train_y.values))),batch_size  = 64)\n",
    "        \n",
    "        metric = metrics.R2Score()\n",
    "        epoch = 0\n",
    "        loss_prev = np.inf\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            start_time = time.time()\n",
    "            total_correct = 0\n",
    "            total_loss = 0\n",
    "            for i, data in enumerate(train_loader, 0):\n",
    "                inputs, labels = data\n",
    "                optimizer.zero_grad() #Set all graidents to zero for each step as they accumulate over backprop\n",
    "                inputs = inputs.view(inputs.shape[0], -1)                \n",
    "                outputs = self.forward(inputs).view(inputs.shape[0])\n",
    "                loss = criterion(outputs,labels)\n",
    "                loss.backward() #computes dloss/dx for every parameter x which has requires_grad=True\n",
    "                optimizer.step() # x += -lr * x.grad ie updates the weights of the parameters\n",
    "                total_loss += loss.item()\n",
    "            end_time = time.time() - start_time\n",
    "            total_loss /= len(self.train_x)\n",
    "            print(\"Epoch no.\",epoch ,\"|total_loss: \", total_loss, \"| epoch_duration: \", round(end_time,2),\"sec\")\n",
    "            # Printing out statistics\n",
    "            if abs(total_loss-loss_prev) < 0.0001:\n",
    "                break\n",
    "            else:\n",
    "                loss_prev = total_loss\n",
    "            \n",
    "        inputs = torch.tensor(self.test_x.values)\n",
    "        labels = torch.tensor(self.test_y.values)\n",
    "        outputs = self.forward(inputs)\n",
    "        outputs = outputs.view(inputs.shape[0])\n",
    "        metricR2 = metrics.R2Score()\n",
    "        metricR2.update(outputs,labels)\n",
    "        metricR2.compute()\n",
    "        print(\"R2\",metricR2.compute())\n",
    "\n",
    "    def predict(self,inputs):\n",
    "        for f in inputs.columns:\n",
    "            inputs[f] = inputs[f].astype(\"float\")\n",
    "        return model.forward(torch.tensor(inputs.values)).view(inputs.shape[0])\n",
    "        \n",
    "def make_orders(predictions,date):\n",
    "    config = kalshi_python.Configuration()\n",
    "    config.host = 'https://demo-api.kalshi.co/trade-api/v2'\n",
    "    client = kalshi_python.ApiInstance(\n",
    "    email=\"mlevine6@bu.edu\",\n",
    "    password= \"in5u>e@t}MaE:mM\",\n",
    "    configuration=config,\n",
    ")\n",
    "    tickers = [\"HIGHNY\",\"HIGHCHI\",\"HIGHMIA\",\"HIGHAUS\"]\n",
    "    for ticker in tickers:\n",
    "        pred = predictions[ticker]\n",
    "        ticker = ticker + \"-\" + date\n",
    "        response = client.get_event(ticker)\n",
    "        temps = [float(o.ticker.split(\"-\")[-1][1:]) for o in response.markets]\n",
    "        diffs = [abs(pred-t) for t in temps]\n",
    "        pick = [o.ticker for o in response.markets][np.argmin(diffs)]\n",
    "        exchangeStatus = client.get_exchange_status()\n",
    "        if exchangeStatus.trading_active:\n",
    "            orderUuid = str(uuid.uuid4())\n",
    "            orderResponse = client.create_order(CreateOrderRequest(\n",
    "                ticker=pick,\n",
    "                action='buy',\n",
    "                type='limit',\n",
    "                yes_price=50,\n",
    "                count=1,\n",
    "                client_order_id=orderUuid,\n",
    "                side='yes',\n",
    "            ))\n",
    "            print(orderResponse)\n",
    "            \n",
    "def update(day):\n",
    "    nyurl = \"https://mesonet.agron.iastate.edu/cgi-bin/request/daily.py?network=NY_ASOS&stations=NYC\"\n",
    "    miaurl = \"https://mesonet.agron.iastate.edu/cgi-bin/request/daily.py?network=FL_ASOS&stations=MIA\"\n",
    "    chiurl = \"https://mesonet.agron.iastate.edu/cgi-bin/request/daily.py?network=IL_ASOS&stations=MDW\"\n",
    "    ausurl = \"https://mesonet.agron.iastate.edu/cgi-bin/request/daily.py?network=TX_ASOS&stations=AUS\"\n",
    "    with open('vars.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "        pday = data[\"prev_day\"]\n",
    "        diff = day - pday\n",
    "        if diff <= 0:\n",
    "            return\n",
    "        url = \"&year1=2024&month1=3&day1=\" + str(pday + 1) + \"&year2=2024&month2=3&day2=\" + str(day) + \"&var=max_temp_f&na=blank&format=csv\"\n",
    "        for city in [\"NY\",\"M\",\"C\",\"A\"]:\n",
    "            u = {\"NY\" : nyurl,\"M\" : miaurl, \"C\" : chiurl,\"A\" : ausurl}[city] + url\n",
    "            r = requests.get(u).text\n",
    "            lines = r.split(\"\\n\")[1:-1]\n",
    "            newlist = data[city]\n",
    "            newlist = newlist[diff:]\n",
    "            for line in lines:\n",
    "                print(line)\n",
    "                newlist.append(float(line.split(\",\")[-1]))\n",
    "            data[city] = newlist\n",
    "        data[\"prev_day\"] = day\n",
    "    with open('vars.json', 'w') as f:\n",
    "        json.dump(data,f)\n",
    "        \n",
    "def load_era5_data(day):\n",
    "    key = \"a5c8c0da0c5f449fb21e280d3b6dbd3a\"\n",
    "    url = 'https://api.oikolab.com/weather'\n",
    "    r = requests.get(url,\n",
    "                     params={'param': ['temperature'],\n",
    "                             'lat': [40.78,41.7,30.2,25.8],\n",
    "                             'lon': [-74,-87.7,-97.7,80.3],\n",
    "                             'location_id': ['NY','C','A','M'],\n",
    "                             'freq' : 'D',\n",
    "                             'start': '2024-03-' + str(day),\n",
    "                             'end': '2024-03-' + str(day)},\n",
    "                     headers={'api-key': key}\n",
    "                     )\n",
    "    a = ast.literal_eval(ast.literal_eval(r.text)[\"data\"])\n",
    "    a = pd.DataFrame(columns = a[\"columns\"], data = a[\"data\"])\n",
    "\n",
    "\n",
    "def load_daily_data(day):\n",
    "    update(day)\n",
    "    a = load_era5_data(day)\n",
    "    with open('vars.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "    M_daily,C_daily,A_daily,NY_daily = data[\"M\"],data[\"C\"],data[\"A\"],data[\"NY\"]\n",
    "    data = pd.DataFrame({\"STATION\":['USW00012839', 'USW00014819', 'USW00013904', 'USW00094728'],\\\n",
    "                  \"Month\":[3,3,3,3],\"days\" : [M_daily,C_daily,A_daily,NY_daily]})\n",
    "    data[[\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]] = \\\n",
    "                data.apply(lambda x : model.month_fun(x[\"Month\"]),axis = 1,result_type=\"expand\")\n",
    "    data[['USW00012839', 'USW00014819', 'USW00013904', 'USW00094728']] =\\\n",
    "                  data.apply(lambda x : model.stat_fun(x[\"STATION\"]),axis = 1, result_type=\"expand\")\n",
    "    gfs = {'USW00012839' : a.loc[0][\"temperature (degC)\"], 'USW00014819' : a.loc[3][\"temperature (degC)\"], 'USW00013904' : a.loc[1][\"temperature (degC)\"] , 'USW00094728' : a.loc[2][\"temperature (degC)\"]}\n",
    "    # data[[\"temp_forecast\"]] =  data.apply((lambda x : gfs[x[\"STATION\"]]* 1.8 + 32),axis = 1, result_type=\"expand\")\n",
    "    for i,row in data.iterrows():\n",
    "        data.at[i,\"Week_av\"] = np.sum(row[\"days\"][-7:])/7\n",
    "        data.at[i,\"2Week_av\"] = np.sum(row[\"days\"][-14:])/14\n",
    "        data.at[i,\"Month_av\"] = np.sum(row[\"days\"])/30\n",
    "        data.at[i,\"d1\"],data.at[i,\"d2\"],data.at[i,\"d3\"],data.at[i,\"d4\"],data.at[i,\"d5\"],data.at[i,\"d6\"],data.at[i,\"d7\"] = row[\"days\"][-7:][::-1]\n",
    "        url = \"&year1=2024&month1=3&day1=\" + str(day) + \"&year2=2024&month2=3&day2=\" + str(day) + \"&var=min_temp_f&var=precip_in&var=max_rh&na=blank&format=csv\"\n",
    "        url2 = \"&year1=2024&month1=3&day1=\" + str(day-1) + \"&year2=2024&month2=3&day2=\" + str(day-1) + \"&var=min_temp_f&var=precip_in&var=max_rh&na=blank&format=csv\"\n",
    "        ud = { 'USW00094728' : \"https://mesonet.agron.iastate.edu/cgi-bin/request/daily.py?network=NY_ASOS&stations=NYC\",\\\n",
    "         'USW00012839' : \"https://mesonet.agron.iastate.edu/cgi-bin/request/daily.py?network=FL_ASOS&stations=MIA\",\\\n",
    "          'USW00014819' : \"https://mesonet.agron.iastate.edu/cgi-bin/request/daily.py?network=IL_ASOS&stations=MDW\",\\\n",
    "         'USW00013904' : \"https://mesonet.agron.iastate.edu/cgi-bin/request/daily.py?network=TX_ASOS&stations=AUS\"}\n",
    "        url = ud[row[\"STATION\"]] + url\n",
    "        url2 = ud[row[\"STATION\"]] + url2\n",
    "        r = requests.get(url).text\n",
    "        r2 = requests.get(url2).text\n",
    "        data.at[i,\"TMIN\"] = float(r.split(\"\\n\")[1].split(\",\")[-3])\n",
    "        data.at[i,\"max_rh\"] = float(r.split(\"\\n\")[1].split(\",\")[-1])\n",
    "        p = r2.split(\"\\n\")[1].split(\",\")[-2]\n",
    "        p = 0 if p == '' else float(p)\n",
    "        data.at[i,\"ry\"] = p\n",
    "        tick = {3:'NY',1:'C',2:'A',0:'M'}[i]\n",
    "        data.at[i,\"temp_forecast\"] = gfs[row[\"STATION\"]] * 1.8 + 32\n",
    "    data.drop([\"Month\",\"STATION\",\"days\"],axis = 1,inplace = True)\n",
    "    data = data[['TMIN', \"ry\",\"max_rh\",'temp_forecast', 'Week_av', '2Week_av',\n",
    "           'Month_av', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'Jan', 'Feb',\n",
    "           'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec',\n",
    "           'USW00012839', 'USW00014819', 'USW00013904', 'USW00094728']]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no. 1 |total_loss:  1.6713355010915119 | epoch_duration:  2.55 sec\n",
      "Epoch no. 2 |total_loss:  0.4815139829405727 | epoch_duration:  2.64 sec\n",
      "Epoch no. 3 |total_loss:  0.4521487478029229 | epoch_duration:  2.56 sec\n",
      "Epoch no. 4 |total_loss:  0.43700898922858356 | epoch_duration:  2.54 sec\n",
      "Epoch no. 5 |total_loss:  0.41139763005811936 | epoch_duration:  2.65 sec\n",
      "Epoch no. 6 |total_loss:  0.37677811586586274 | epoch_duration:  2.61 sec\n",
      "Epoch no. 7 |total_loss:  0.35082945595523524 | epoch_duration:  2.61 sec\n",
      "Epoch no. 8 |total_loss:  0.3170277943899437 | epoch_duration:  2.63 sec\n",
      "Epoch no. 9 |total_loss:  0.29274628828729443 | epoch_duration:  2.7 sec\n",
      "Epoch no. 10 |total_loss:  0.2777702021348956 | epoch_duration:  2.63 sec\n",
      "Epoch no. 11 |total_loss:  0.2711875294852956 | epoch_duration:  2.65 sec\n",
      "Epoch no. 12 |total_loss:  0.2651355466134342 | epoch_duration:  2.69 sec\n",
      "Epoch no. 13 |total_loss:  0.2619869564961213 | epoch_duration:  2.57 sec\n",
      "Epoch no. 14 |total_loss:  0.258442246492392 | epoch_duration:  2.83 sec\n",
      "Epoch no. 15 |total_loss:  0.25595099091642487 | epoch_duration:  2.95 sec\n",
      "Epoch no. 16 |total_loss:  0.25363583224495356 | epoch_duration:  2.95 sec\n",
      "Epoch no. 17 |total_loss:  0.251576622075458 | epoch_duration:  2.8 sec\n",
      "Epoch no. 18 |total_loss:  0.24938951610618398 | epoch_duration:  2.65 sec\n",
      "Epoch no. 19 |total_loss:  0.24723725431394394 | epoch_duration:  2.69 sec\n",
      "Epoch no. 20 |total_loss:  0.24576061009862396 | epoch_duration:  2.63 sec\n",
      "Epoch no. 21 |total_loss:  0.24429433638940432 | epoch_duration:  2.67 sec\n",
      "Epoch no. 22 |total_loss:  0.243338147359961 | epoch_duration:  2.65 sec\n",
      "Epoch no. 23 |total_loss:  0.24182117924720903 | epoch_duration:  2.67 sec\n",
      "Epoch no. 24 |total_loss:  0.2408969231955243 | epoch_duration:  2.58 sec\n",
      "Epoch no. 25 |total_loss:  0.23964942330127265 | epoch_duration:  2.76 sec\n",
      "Epoch no. 26 |total_loss:  0.23827343565432682 | epoch_duration:  2.72 sec\n",
      "Epoch no. 27 |total_loss:  0.2381405548891619 | epoch_duration:  2.71 sec\n",
      "Epoch no. 28 |total_loss:  0.23711279922117776 | epoch_duration:  2.88 sec\n",
      "Epoch no. 29 |total_loss:  0.23657171623570716 | epoch_duration:  2.75 sec\n",
      "Epoch no. 30 |total_loss:  0.23609438154882914 | epoch_duration:  2.86 sec\n",
      "Epoch no. 31 |total_loss:  0.23509882585631364 | epoch_duration:  2.82 sec\n",
      "Epoch no. 32 |total_loss:  0.234757055060823 | epoch_duration:  2.64 sec\n",
      "Epoch no. 33 |total_loss:  0.23425563455769058 | epoch_duration:  2.75 sec\n",
      "Epoch no. 34 |total_loss:  0.23331188695326815 | epoch_duration:  2.91 sec\n",
      "Epoch no. 35 |total_loss:  0.23313203486185052 | epoch_duration:  2.79 sec\n",
      "Epoch no. 36 |total_loss:  0.23252613935704194 | epoch_duration:  2.75 sec\n",
      "Epoch no. 37 |total_loss:  0.23225215263227297 | epoch_duration:  2.71 sec\n",
      "Epoch no. 38 |total_loss:  0.23204149092787194 | epoch_duration:  2.77 sec\n",
      "Epoch no. 39 |total_loss:  0.2310498106813258 | epoch_duration:  2.64 sec\n",
      "Epoch no. 40 |total_loss:  0.2304089655230548 | epoch_duration:  2.74 sec\n",
      "Epoch no. 41 |total_loss:  0.23026921672163037 | epoch_duration:  2.72 sec\n",
      "Epoch no. 42 |total_loss:  0.22978968987383191 | epoch_duration:  2.75 sec\n",
      "Epoch no. 43 |total_loss:  0.22911202218876148 | epoch_duration:  2.8 sec\n",
      "Epoch no. 44 |total_loss:  0.2287398353326223 | epoch_duration:  2.77 sec\n",
      "Epoch no. 45 |total_loss:  0.22860994036515872 | epoch_duration:  2.76 sec\n",
      "Epoch no. 46 |total_loss:  0.22795463053851456 | epoch_duration:  2.86 sec\n",
      "Epoch no. 47 |total_loss:  0.22785117232069277 | epoch_duration:  2.89 sec\n",
      "Epoch no. 48 |total_loss:  0.22729508990504999 | epoch_duration:  2.87 sec\n",
      "Epoch no. 49 |total_loss:  0.2269913494762887 | epoch_duration:  2.63 sec\n",
      "Epoch no. 50 |total_loss:  0.2267790346512576 | epoch_duration:  2.71 sec\n",
      "Epoch no. 51 |total_loss:  0.22663727594660088 | epoch_duration:  2.71 sec\n",
      "Epoch no. 52 |total_loss:  0.22629170671521917 | epoch_duration:  2.78 sec\n",
      "Epoch no. 53 |total_loss:  0.22611093506285787 | epoch_duration:  2.86 sec\n",
      "Epoch no. 54 |total_loss:  0.2257657036095844 | epoch_duration:  2.84 sec\n",
      "Epoch no. 55 |total_loss:  0.22556036130866475 | epoch_duration:  2.59 sec\n",
      "Epoch no. 56 |total_loss:  0.22547223204703057 | epoch_duration:  2.73 sec\n",
      "R2 tensor(0.9551)\n"
     ]
    }
   ],
   "source": [
    "features = [\"TMIN\",\"ry\",\"max_rh\",\"temp_forecast\",\"Week_av\",\"2Week_av\",\"Month_av\"]\n",
    "for i in range(1,8):\n",
    "    features.append(\"d\" + str(i))\n",
    "model = NN(30,48,24)\n",
    "model.load_data(\"./data/for_1965_2024.csv\",features,\"TMAX\")\n",
    "model.train()\n",
    "torch.save(model.state_dict(),\"NNModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TMIN      ry     max_rh  temp_forecast    Week_av   2Week_av   Month_av  \\\n",
      "0  64.0  1.5500  83.781500         87.476  77.142857  80.214286  80.633333   \n",
      "1  33.0  0.0001  58.558560         37.436  38.714286  50.571429  53.166667   \n",
      "2  56.0  0.0000  96.463680         63.554  60.428571  68.214286  72.633333   \n",
      "3  31.0  3.6600  56.270382         37.400  43.857143  53.285714  52.833333   \n",
      "\n",
      "     d1    d2    d3  ...  Jul  Aug  Sep  Oct  Nov  Dec  USW00012839  \\\n",
      "0  76.0  74.0  75.0  ...  0.0  0.0  0.0  0.0  0.0  0.0          1.0   \n",
      "1  44.0  37.0  37.0  ...  0.0  0.0  0.0  0.0  0.0  0.0          0.0   \n",
      "2  64.0  65.0  59.0  ...  0.0  0.0  0.0  0.0  0.0  0.0          0.0   \n",
      "3  44.0  49.0  36.0  ...  0.0  0.0  0.0  0.0  0.0  0.0          0.0   \n",
      "\n",
      "   USW00014819  USW00013904  USW00094728  \n",
      "0          0.0          0.0          0.0  \n",
      "1          1.0          0.0          0.0  \n",
      "2          0.0          1.0          0.0  \n",
      "3          0.0          0.0          1.0  \n",
      "\n",
      "[4 rows x 30 columns]\n",
      "{'HIGHNY': 44.866043178543364, 'HIGHCHI': 52.15581561670643, 'HIGHMIA': 79.11977584391909, 'HIGHAUS': 75.16645079871384}\n"
     ]
    }
   ],
   "source": [
    "model = NN()\n",
    "model.load_state_dict(torch.load(\"NNModel\"))\n",
    "data = load_daily_data(24)\n",
    "print(data)\n",
    "preds = model.predict(data)\n",
    "preds = {\"HIGHNY\" : preds[3].item(),\"HIGHCHI\": preds[1].item(),\"HIGHMIA\" : preds[0].item(),\"HIGHAUS\" : preds[2].item()}\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'order': {'action': 'buy',\n",
      "           'client_order_id': '91bc8572-4d0e-49cf-83be-ca17a5b2c68e',\n",
      "           'created_time': '2024-03-24T17:32:25.856246Z',\n",
      "           'expiration_time': None,\n",
      "           'no_price': 50,\n",
      "           'order_id': '565b7b48-05a3-4841-8fc1-7cc8dc22ce28',\n",
      "           'side': 'yes',\n",
      "           'status': 'executed',\n",
      "           'ticker': 'HIGHNY-24MAR24-B45.5',\n",
      "           'type': 'limit',\n",
      "           'user_id': '9ac6156d-6869-47cf-ba13-74df1b5e51f8',\n",
      "           'yes_price': 50}}\n",
      "{'order': {'action': 'buy',\n",
      "           'client_order_id': '3f79099d-d9de-4c5f-bd66-25c6f76f623d',\n",
      "           'created_time': '2024-03-24T17:32:26.152716Z',\n",
      "           'expiration_time': None,\n",
      "           'no_price': 50,\n",
      "           'order_id': '958b94fb-ee57-4a1f-bf1e-4107f0c0ea29',\n",
      "           'side': 'yes',\n",
      "           'status': 'executed',\n",
      "           'ticker': 'HIGHCHI-24MAR24-T49',\n",
      "           'type': 'limit',\n",
      "           'user_id': '9ac6156d-6869-47cf-ba13-74df1b5e51f8',\n",
      "           'yes_price': 50}}\n",
      "{'order': {'action': 'buy',\n",
      "           'client_order_id': 'b23d733a-7b6f-4dc2-acbe-9ddf2f64e434',\n",
      "           'created_time': '2024-03-24T17:32:26.426234Z',\n",
      "           'expiration_time': None,\n",
      "           'no_price': 50,\n",
      "           'order_id': 'be3a786e-90b0-4af8-9e54-eb4c457ce7eb',\n",
      "           'side': 'yes',\n",
      "           'status': 'resting',\n",
      "           'ticker': 'HIGHMIA-24MAR24-B79.5',\n",
      "           'type': 'limit',\n",
      "           'user_id': '9ac6156d-6869-47cf-ba13-74df1b5e51f8',\n",
      "           'yes_price': 50}}\n",
      "{'order': {'action': 'buy',\n",
      "           'client_order_id': '2317c230-5b5f-484a-9981-a02233823200',\n",
      "           'created_time': '2024-03-24T17:32:26.793597Z',\n",
      "           'expiration_time': None,\n",
      "           'no_price': 50,\n",
      "           'order_id': '7f0f8e51-47b4-44cb-aaa6-90173dd15875',\n",
      "           'side': 'yes',\n",
      "           'status': 'executed',\n",
      "           'ticker': 'HIGHAUS-24MAR24-B74.5',\n",
      "           'type': 'limit',\n",
      "           'user_id': '9ac6156d-6869-47cf-ba13-74df1b5e51f8',\n",
      "           'yes_price': 50}}\n"
     ]
    }
   ],
   "source": [
    "make_orders(preds,\"24MAR24\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"for_1965_2024.csv\")\n",
    "model = NN(30,48,24)\n",
    "model.load_state_dict(torch.load(\"NNModel\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
